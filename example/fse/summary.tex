%\ma{Video games?}

%\begin{figure*}
%\begin{tabularx}{\textwidth}{|X|X|X|X|}
%\hline
%Case Study   & Description & Why protecting variability? & Protecting mechanisms \\ \hline
%Bref         &    an online video generator that plays humoristic video variants based on some users' choices and random choices &                       
%data protection (videos copyright); software protection (frequency distribution, access to data); discovery of variability may kill the "surprise" effect and kill the interest of the generator
% & demodularizing modularity; protections to limit the crawling of the configuration space             \\ \hline
% Newspapers   & online newspapers with four variants (for regular readers, members, journalists, web engine) & privilege access to content & everything in one place; feature interactions \\ \hline
%Windows 7    &     an operating system coming in different variants ("upgrades")       &  free upgrade                           & everything in one place                       \\ \hline
%%Automotive   &    embedded code in vehicles      &        may contain hidden features that can be activated                     &                       \\ \hline
%Configurator &    web configurators assist customers in selecting options and eventually choose a product &        marketing or technical constraints may be discovered; business intelligence;       &      protections to limit the static analysis of configuration options; to limit crawling of the configuration space                   \\ \hline
%\end{tabularx}
%\caption{Case studies}
%\end{figure*}
%
%\begin{itemize}
%\item barriers to crawling the configuration space 
%\item the danger of putting everything in one place
%\item obfuscation/demodularizing (code + data + mapping)
%\end{itemize}




% Previous section shows that possible vulnerabilities in the implementation of product lines can jeopardize trade secrets. 
We observe that the case studies are sharing similar classes of security and protection issues.
We identify three kinds of vulnerabilities (related to positive variability, negative variability, or configuration space) and leading to the possible leaks of trade secrets. 
We draw a research roadmap highlighting four directions (RD1, RD2, RD3, RD4).
% calling to investigate protection mechanisms.
% The overall challenge is to cross fertilize the research results in software product lines and security to efficiently protect variability.

% A tentative classification of these vulnerabilities can be done according to the use of either positive or negative variability. In this section, we classify the previous vulnerabilities according to these two use of variability, and we give some insights on how they would be consider to be protected according to the kind of variability implemented. In both cases,  
\rro{Protection of positive variability (RD1)} Voelter \etal describe variability implemented with \emph{compositional} approaches as positive variability since variable elements are added together~\cite{voelter2007}. 
It is the case of the video generator case study (see Section~\ref{sec:casestudy2}) in which video sequences are assembled to build a video variant. 
It may also be the case in Web configurators (see Section~\ref{sec:casestudy4}) in which options are added on-the-fly depending on some user choices. 

We have shown in Section~\ref{sec:casestudy2} that an attacker can too easily reverse engineer the product line with a clean modularization design. 
The vulnerabilities are coming from the identification of the modules and their direct mapping in terms of features in the variability model. From this identification, an attacker can infer how these modules can be composed together to re-engineer the product line (\ie by positive variability). 
It should be noted that the positive variability (and the underlying issues) apply either at the data level (e.g., videos) or at the implementation level (source code) of the product line. Two main approaches are then possible to prevent the discovery of trade secrets. 

First, source code deconstruction, such as control flow degeneration and data flow disturbance, are essential obfuscation techniques~\cite{collberg1997taxonomy}. 
% They can prevent reverse engineering and code tampering to protect intellectual property and business secrets. 
% Source code deconstruction, such as control flow degeneration and data flow disturbance, are essential techniques for code obfuscation. 
% For an overview on code obfuscation, we refer to the now classical taxonomy by Collberg and colleagues~.  
 An open challenge is to develop techniques for obfuscating specifically the variability and modularity in the source code or data.  
%
 A second approach is to obfuscate the \emph{mapping} between features/options and the corresponding artefacts. 
For instance, a one-to-one mapping may be too easy to identify and understand. 
The challenge is to develop innovative techniques, ideally non intrusive for product line developers and agnostic to a domain, for diversifying the mapping. 
 %  of the modules in terms of feature in the variability model \todos{here give more from the previous paper}. 
The two approaches can be used independently or in combination, depending on the product line characteristics. % of the product line.

% The first category consists in obfuscating the source code and the data. 

% \emph{Data obfuscation} aims at obscuring the purpose of the artefacts and the data structures that a program manipulates during its execution~\cite{naumovich2003preventing}.
% In~\cite{collberg1998breaking} several techniques are proposed to demodularize Java classes and data types by breaking their structures. In particular, they propose to split % or merge arrays. We can relate this example to our case study as we also propose to split or merge sequences of videos.
% The main difference with our work is the nature of the data. In our case, we consider the demodularization of external artefacts such as video files instead on focusing on the internal variables and data structures of a program.


%Why is obfuscation a kind of diversification?
% A basic obfuscation technique simply transforms a program $P$ in a program $P'$ which is distributed. 
 % Since obfuscation is automated, it is often possible to generate several different obfuscated versions of the same program (as proposed by Collberg \etal~\cite{collberg12} for example).
% Wang \etal \cite{wang01} propose a multi-level program transformation that aims at degenerating  the control flow so as to provide in-depth obfuscation. %This work on program transformation takes place in the context of a software architecture for survivable systems as proposed by Knight et al. \cite{knight00}. 
% Wang's approach consists in two main steps: transform all high-level control flow structures in \emph{if-then-goto} structures; introduce aliases in the goto statements so that the goto address is determined only at runtime.
%In both cases, this kind of technique results in a semantic diversity of execution profiles, and consequently is deeply related to automated diversity.
%  Another approach consists in letting programs self-modify. These programs embed a runtime randomization technique \cite{mavrogiannopoulos2011taxonomy}, which will modify the binary code in way that attackers cannot retrieve the structure of the control or data flow. This is done for sake of security and is considered one of the strongest obfuscation mechanism~\cite{mavrogiannopoulos2011taxonomy}. 
%
 
 
 
% security purposes to (1) external data operated by a program (e.g., as needs be in our case study); (2) adapt or generate the code in charge of accessing de-modularized data. 

% ~\cite{DBLP:series/ais/Rinard11}
% 
% ~\cite{DBLP:conf/aosd/Rinard12}

% \subsection{}
% Altering the source code initially developed, either at compile or at runtime, is a common approach that was already investigated for other non functional properties than security (e.g., performance).
% For example, in the context of quality of service, 
 % Sidiroglou \etal~\cite{Sidiroglou-Douskos2011} have introduced loop perforation and shown that in some domains it is possible to skip the execution of loop iterations. 
% For instance, in a video decoding algorithm (codec), skipping some loop iterations has an effect on some pixels or contours but does not further degrade or crash the software application. On the other hand, skipping loop iterations is key with respect to performance. 
% In other words, it is possible to manipulate a program's functionality to handle performance or  security issues~\cite{Rinard11}. This trade-off can be set offline (e.g. by arbitrarily skipping one every two loops) or dynamically based on the current load of the machine or intrusion detection.

% This approach is also intensively used in the context of optimizing compilers that try to optimize some properties in the generated code (e.g., execution time or memory consumption). Such approaches that act at compile time apply some static analysis of the source code, and adapt the design for optimization purpose. For example, the polyhedral model \cite{quillere2000} is commonly used for loop nest optimization to detect where a set of loop transformations can be applied for the purpose of locality optimization or parallelization.

% Besides, numerous techniques have been proposed to automate the remodularization of an existing software project~\cite{DuBois2004,Bryton2008,Zanetti2014,Goldstein2014}. The goal is rather to improve modularity properties, for instance, to ease the maintenance of an application. 

% All exposed techniques in this section offer \emph{demodularizing} mechanisms. Some of them have different goals and do not necessarily target security issues. We believe some of these techniques could be applied for our class of problem. 


% The challenge is to develop 
% and are complementary. 
 

%, e.g., decomposition into module \todos{here give more from the previous paper}. 




% once and for all
% at once
% straightaway
% right from the beginning
\rro{Protection of negative variability (RD2)} Some product lines exhibit all their functionality and content once and for all. They use \emph{negative} variability (as opposed to the previous positive variability) in which all different variants are expressed; the variants are activated depending on some conditions. 
It is the case of online newspapers (see Section~\ref{sec:casestudy1}). 
%  and the Windows family (see Section~\ref{sec:casestudy3}). 
 It may also be the case in Web configurators (see Section~\ref{sec:casestudy4}) in which options are hidden or depicted on-the-fly depending on some user choices. The source code of such configurators already contains the content for activating/deactivating options typically through JavaScript. 
% Web configurators (see Section~\ref{sec:casestudy4}) in which options are added on-the-fly depending on some user choices. 
% Scenarios Z and ZZ have shown vulnerabilities in the particular configuration of a given product. In this case, the initial product provide all the features which are restricted according to the expected features (aka. negative variability). 
 Negative variability cannot be accused of being the root cause of vulnerabilities. However, it is necessary to either:
\emph{(1)} improve the mechanism used to remove or activate some variants. For instance, access controls (e.g., at the server side) or obfuscations can be considered; \emph{(2)} obfuscate the pre-defined variants. For example, in the case of online newspapers, the content of members' articles can be encrypted.
% \end{itemize}
% To prevent the identification of the possible configurations, 

% \todos{here give more from the previous paper}. 

An interesting research direction is to determine whether (and if yes, when) negative variability presents more security guarantees than positive variability (or the other way around). Product lines can indeed use the two kinds of variability (\eg as in Web configurators). 

\rro{Barriers to master the configuration space (RD3)} Understanding a configuration set may have an interest \emph{per se} since trade secrets are hidden there. 
For example, the video generator of Section~\ref{sec:casestudy2} has a strategy for generating some frequencies of features. The idea is that some features corresponding to some video sequences are rarely activated (e.g., in 0.1\% of configuration) for surprising the visitor. 
As another example, Web configurators exhibit options with marketing or technical constraints. 
In the two examples, the ability of an attacker to crawl the configuration space is the key for discovering trade secrets. The more, better it is. A \emph{comprehensive} visit is the worst situation since the extracted knowledge is then complete. %
 Another threat of a (comprehensive) mastering of the configuration space is that attacker can experiment the effects the configurations have on the product line. 
It is one of the basis to understand or guess the underlying implementation of a product line.
% For example, setting specific configuration settings in the registry of Windows (see Section~\ref{sec:casestudy3}) proves to give access to some features of the product line. 
 In the video generator, setting a configuration leads to a new video variant that can be then analyzed. 
A comprehensive visit is again the worst situation since all corresponding variants and related artefacts are then accessible.

%  a configuration set may have 

% In the two aforementioned categories, discovering the modularization or removal mechanism of the features leads to the identification of the set of configurations that this mechanism can support. However, this does not allow an attacker to identify the particular constraints between certain features, preventing certain undesirable configurations. Such constraints can be discovered by 
The challenge of RD3 is to develop barriers to limit the exploration of the configuration space. 
For instance, some mechanisms for blocking temporarily internet protocol addresses can be considered in case many requests for crawling the configuration space are observed (see Section~\ref{sec:casestudy2}). Many specific factors can influence the definition of a politics of configuration access. % limiting accesses is specific to a product line since




% systematically exploring the set of configurations on the system (or by using more sophisticated algorithm to limit the exploration space). To address this issue, it is necessary to prevent the systematic exploration of the configurations, depending on the intended use of the product line. 

% For example ...

\rro{RD4: Cost-benefit tradeoffs} On the one hand, protecting variability and configurations has admittedly a cost. 
The technical or management effort can be more or less important -- from a drastic change in the design of the product line to small increments to re-enforce access controls. 
On the other hand, the trade secrets an organization has to protect and the possible consequences highly vary. A trade secret can give access to very few non-members, but can also lead to lose any competing advantage. 

Hence a tradeoff has to be found. The importance of trade secrets a product line can jeopardize should justify the investments required to develop and deploy protecting mechanisms. A spectrum of more or less sophisticated techniques can thus emerge. 
% An expected quality (and challenge) is to have 
 An ideal solution (hence a challenge) is to let product line developers follow their usual methods while guaranteeing adequate security. % configurations
 
% of deriving the individual products during application engineering

% to the lose of millions of customers 



%\subsection{\mechvar}
%
%% 
%
%We now discuss some defensive protection strategies in the context of our case study. 
%In particular, as modularity is exposing security threats, we define and describe possible \emph{demodularization} mechanisms, i.e., disruptive mechanisms capable of adapting the original modularity.
%
%\subsubsection{Basic Protection}
%
%\ma{emphasize that protection is to (1) limit "configuration crawling" (2) obfuscate the "code" (not the data) so that we can have difficulties to understand the variability implementation}
%
%Numerous protections exist against reverse engineering or illegal access, in particular in the domain of Web applications as in our case study.
%For instance, it is possible to forbid suspicious connections and block temporarily some internet protocol addresses. 
%An attacker can have difficulties to explore the modularity space. 
%
%Another basic strategy is to obfuscate client code (JavaScript) to make the attacker's tasks harder. 
%A first obstacle is that obfuscation may have some limits and debuggers can partially reduce the desired effect. Another severe limitation -- the most important one -- is that the behaviour logic is also visible through communication traces (HTTP requests) with the server. 
%% More generally obfuscation 
%% not only expressed at the JavaScript 
% 
%Actually, these two protections were enabled in our case study. But an attacker is still able to reverse engineer the service and get access to the videos. 
%In fact, these techniques try to hinder a possible reverse engineering but do not hide all forms of modularity present in other artefacts (e.g., video playlist).
%This motivates the need for techniques that hide or transform the original modularity of data and code as perceived by an attacker.
%
%\subsubsection{Demodularization and Heartbreaking} 
%
%\ma{we have to reduce}
%
%A first technique would be to remove all or part of the modularity in a video.
%In our example, it would result in \emph{merging} all the video sequences on the server side. 
%That is, a video variant would then consist in one and unique sequence instead of 18. 
%
%With such demodularization strategy, there is no need for playlists and video sequences. 
%A benefit is that the attacker has only access to a full, monolithic video variant at a time; the modularity units are no longer present, complicating the reverse engineering process. %task  
%% This heavily complicates the task of an attacker.
% Let say, in this context, an attacker still wants to understand what are the alternatives for each portion of the video. He or she would have to download numerous video variants, and then find commonalities and differences between portions of the videos. The difference of two or more than two videos is not an easy task, requiring to rely on image processing algorithms. A manual review is also needed to specify when and how the video sequences should be cut (the length of alternatives varies). 
% 
% % especially in the case study where alternatives significantly differ. 
%
%% and finally detect the sequences.
%Though appealing, the idea of merging video sequences has significant drawbacks. The operation should be realized in the server side for assembling video sequences. It is resource and time-consuming, precluding a reactive, scalable service. A more subtle strategy would be \emph{pre-}generate and store the video variants before a client's request. Generating all the video variants is not feasible as it represents billions of videos. 
%This technique also significantly increases the needs for computation power and storage of the hosting infrastructure.
%
%Overall the demodularization strategy exposed in this subsection has severe drawbacks since all good properties of modularization are lost. 
%
%\subsubsection{Varying Variability Through Demodularization Strategies}
%% Demodularizing Strategies} 
%%\section{}
%
%\ma{we have to reduce}
%
%Other strategies can be considered to adapt the modularity of the video generator so that an attacker either (1) perceives differently and wrongly the original modularity or (2) has severe difficulties to recover and understand the original modularity.  
%
%
%For instance a disruptive technique is to artificially increase the modularity. For example, the server can (randomly):
%\begin{itemize}
%\item add empty videos to the playlist;
%\item change the order of the videos;
%\item modify file names associated to video sequences.
%\end{itemize}
%
%% is it more like shifting modularity?
%
%Another technique is to change the modularity structure. For example, the cutting of video sequences can vary. 
%% be implemented differently -- conceptually stay at 18 
% Instead of observing 18 video sequences, an attacker would observe, say, 9 sequences. 
%This time, 9 playlists associated to the 9 sequences would actually be constituted of two playlists of successive alternatives.  
%More sophisticated combinations can be envisioned as well while the cutting can be randomly shifted for each client. As a result, an attacker would see a different structure at each request. But internally and eventually the video variants would still be assembled as 18 video sequences. 
%The benefit is that an attacker will have severe difficulties to identify and locate the modularity units, because of a random modification of the modularity structure. 
% 
% % It would hinder the access to all the videos and thus the re-engineering of a new service.
%
%Overall, breaking the modularity of the original service can increase its security as it highly disrupts the comprehension of modularity by attackers. 
%However, we note that breaking the modularity at design time may directly impact the development of the application. That is, more engineering effort may be needed to realize an efficient demodularization technique. In some cases, the demodularization involves the modification of different artefacts (e.g., JavaScript source code, generation of video playlists) in the server side and the client side.
%% This may even lead to go against fundamental guidelines of software engineering. % cancel the benefits of building a modular application and 
%
% Therefore, the focus should be put on generative techniques that act later in the lifetime of an application (\eg at compile or run time). This would allow to keep good properties of modularity when developing and still have a more secured application. %  with respect to modularity.

